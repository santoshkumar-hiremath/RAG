This repository contains a high-performance Retrieval-Augmented Generation (RAG) pipeline designed to centralize technical intelligence. It bridges the gap between static local documentation and dynamic cloud-based knowledge from the HPE Confluence Wiki.üöÄ Quick Start: Execution OrderTo ensure the system has the latest data and correct access, follow this specific sequence:1. AuthenticateRun this to handle Okta/SSO authentication.Bashpython auth_session.py
What it does: Opens a visible browser for you to log in manually.Output: Saves a storage_state.json file containing your session tokens. You only need to re-run this if your session expires.2. Ingest & IndexRun this to build the "brain" of the AI.Bashpython ingest.py
What it does: Scans /data_files (PDF, TXT, DOCX) and recursively crawls the Project PCAI Wiki.Output: Generates combined_index.faiss and metadata.json. It also creates a scraped_data_cache.json for faster subsequent runs.3. Launch the UIRun this to start the Q&A interface.Bashstreamlit run app.py
What it does: Opens a web interface where you can ask technical questions. The AI will search the index and provide cited, step-by-step answers.üõ† Project ComponentsScriptPurposeauth_session.pyAuthenticator: Manages secure SSO session persistence.ingest.pyProcessor: Handles scraping, text chunking ($1200$ chars), and vector embedding.app.pyInterface: Streamlit UI for querying the Llama 3 model via Ollama.üß† Technical StackLLM: Llama 3 (via Ollama) ‚Äî Runs locally for 100% data privacy.Embeddings: all-MiniLM-L6-v2 ‚Äî High-speed semantic mapping.Vector Store: FAISS ‚Äî Sub-millisecond similarity search.Automation: Playwright ‚Äî Navigates and renders JavaScript-heavy Confluence pages.Acceleration: Automatically uses Mac MPS (Metal Performance Shaders) for GPU-accelerated indexing.üí° Key FeaturesRecursive Discovery: Automatically finds and indexes child pages in the CPC Wiki space.Hydration Awareness: Waits for Confluence JavaScript to fully load before scraping, ensuring no "Loading..." placeholders are indexed.Semantic Integrity: Uses a $200$-character chunk overlap to ensure technical context isn't lost at the boundaries.Negative Constraints: The AI is strictly tuned to say "Information not provided" if the answer is not found in the documents, preventing hallucinations.üìÅ Directory Structure/data_files: Drop your local PDFs, DOCXs, and TXTs here.storage_state.json: Encrypted session tokens (generated by auth_session.py).combined_index.faiss: The generated vector database.metadata.json: Mapping of text chunks to their original sources/URLs.
